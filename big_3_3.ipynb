{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/userkki/Py_Project/blob/main/big_3_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VsjPq7tSkJ64",
        "outputId": "4a981b1d-cd57-4dcd-850a-80ea99d68fe5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[15:56:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[15:56:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[15:56:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[15:56:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[15:56:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[0.76744186 0.80666667 0.78333333 0.8        0.79      ]\n",
            "Mean cross_value_score : 0.789\n",
            "[15:56:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "0.9058032717718583 0.9823101854515467\n",
            "0.9260493004663558\n",
            "       ID  prict_prob\n",
            "0    1501    0.123108\n",
            "1    1502    0.035674\n",
            "2    1503    0.250659\n",
            "3    1504    0.001145\n",
            "4    1505    0.400671\n",
            "..    ...         ...\n",
            "481  1982    0.987850\n",
            "482  1983    0.082569\n",
            "483  1984    0.012184\n",
            "484  1985    0.989980\n",
            "485  1986    0.209598\n",
            "\n",
            "[486 rows x 2 columns]\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "X = pd.read_csv('3rd_TravelInsurancePrediction_train.csv')\n",
        "y_test = pd.read_csv('3rd_TravelInsurancePrediction_test.csv')\n",
        "#print(X.shape, y_test.shape)\n",
        "#print(X.head())\n",
        "#print(y_test.head())\n",
        "y_test_id = y_test.iloc[:, 0:1]\n",
        "#print(y_test_id.info())\n",
        "y_train = X.iloc[:, -1:]\n",
        "#print(y_train.info())\n",
        "#print(X['Employment Type'].unique())\n",
        "X_train = X.iloc[:, 1:9]\n",
        "y_test = y_test.drop(columns = ['ID'])\n",
        "#print(X_train.head())\n",
        "#print(y_test.head())\n",
        "X_train = pd.get_dummies(X_train, drop_first = True)\n",
        "y_test = pd.get_dummies(y_test, drop_first = True)\n",
        "#print(X_train.shape, y_test.shape)\n",
        "#print(X_train.head())\n",
        "#print(y_test.head())\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import KFold, cross_val_score\n",
        "from sklearn.metrics import roc_auc_score, mean_squared_error\n",
        "model1 = RandomForestClassifier()\n",
        "model = XGBClassifier(n_estimators = 300)\n",
        "#model = XGBClassifier()\n",
        "kfold = KFold(n_splits = 5, random_state = 42, shuffle = True)\n",
        "scores = cross_val_score(model, X_train, y_train, cv = kfold)\n",
        "print(scores)\n",
        "print('Mean cross_value_score : {:.3f}'.format(scores.mean()))\n",
        "model.fit(X_train,y_train)\n",
        "score_train = model.score(X_train, y_train)\n",
        "pred_train = model.predict(X_train)\n",
        "prob_train = model.predict_proba(X_train)\n",
        "prob_train1 = pd.DataFrame(prob_train).iloc[:, 1:]\n",
        "#print(prob_train)\n",
        "roc_score1 = roc_auc_score(y_train, pred_train)\n",
        "roc_score2 = roc_auc_score(y_train, prob_train1)\n",
        "print(roc_score1, roc_score2)\n",
        "print(score_train)  \n",
        "\n",
        "pred_test = model.predict(y_test)\n",
        "prob_test = model.predict_proba(y_test)\n",
        "prob_test1 = pd.DataFrame(prob_test).iloc[:, 1:]\n",
        "submit = pd.concat([y_test_id, prob_test1], axis = 1)\n",
        "#print(submit)\n",
        "submit1 = submit.rename(columns = {1 : 'prict_prob'})\n",
        "submit2 = pd.DataFrame({'ID' : y_test_id.to_numpy, 'prob_test1' : pred_test})\n",
        "#print(submit1) \n",
        "submit1.to_csv('12345.csv', index = False)\n",
        "confirm = pd.read_csv('12345.csv')\n",
        "print(confirm)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "56znX-pwkJ67"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "big_3_3.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}